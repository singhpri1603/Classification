{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def naiveB():\n",
    "    data0_indices = np.argwhere(Xtrain[:,numCols-1] == '0')\n",
    "    data0 = Xtrain[data0_indices[:,0],:numCols-1]\n",
    "    #print \"Class 0: \"+ str(data0.shape)\n",
    "\n",
    "    data1_indices = np.argwhere(Xtrain[:,numCols-1] == '1')\n",
    "    data1 = Xtrain[data1_indices[:,0],:numCols-1]\n",
    "    #print \"Class 1: \" + str(data1.shape)\n",
    "    prior0 = float(data0.shape[0])/float(Xtrain.shape[0])\n",
    "    prior1 = float(data1.shape[0]/float(Xtrain.shape[0]))\n",
    "    #print \"Prior probability of 0: \" + str(prior0)\n",
    "    #print \"Prior probability of 1: \" + str(prior1)\n",
    "    a = b = c = d = 0\n",
    "   \n",
    "    for i in range(Xtest.shape[0]):\n",
    "        #print \"Point is :\" + str(Xtest[i])\n",
    "        #print \"For data0 :\"\n",
    "        p0 = singlePost(Xtest[i], data0)\n",
    "        #print \"For data1 :\"\n",
    "        p1 = singlePost(Xtest[i], data1)\n",
    "        \n",
    "        #print \"p0 = \" + str(p0)\n",
    "        #print \"p1 = \" + str(p1)\n",
    "        \n",
    "        p0 = prior0 * p0\n",
    "        p1 = prior1 * p1\n",
    "        \n",
    "        if (p1/p0) > 1:\n",
    "            #classified as 1\n",
    "            #print p1/p0\n",
    "            if Xtest[i, Xtest.shape[1]-1] == '1':\n",
    "                a = a+1\n",
    "            else:\n",
    "                c = c+1\n",
    "        else:\n",
    "            #classified as 0\n",
    "            #print p1/p0\n",
    "            if Xtest[i, Xtest.shape[1]-1] == '0':\n",
    "                d = d+1\n",
    "            else:\n",
    "                b = b+1\n",
    "    print str(a) +\",\"+ str(b) +\",\"+ str(c) +\",\"+ str(d)\n",
    "    metrics(a,b,c,d)\n",
    "    #print str(a) +\",\"+ str(b) +\",\"+ str(c) +\",\"+ str(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def singlePost(point, datai):\n",
    "    p = 1\n",
    "    for j in range(point.shape[0]-1):\n",
    "        tempProb = np.argwhere(datai[:,j] == point[j]).shape[0]\n",
    "        tempProb = tempProb+1 # Laplacian Correction\n",
    "        tempProb = float(tempProb)/float(datai.shape[0]+(point.shape[0]-1))\n",
    "        p = p*tempProb\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def metrics(a, b, c, d):\n",
    "    accuracy = float(a + d)/float(a+b+c+d)\n",
    "    if(a == 0 and c == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = float(a)/float(a+c)\n",
    "    if(a == 0 and b == 0):\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = float(a)/float(a+b)\n",
    "    if(a == 0 and b == 0 and c == 0):\n",
    "        fmeasure = 0\n",
    "    else:\n",
    "        fmeasure = float(2*a)/float(2*a + b + c)\n",
    "    global accuracy_avg\n",
    "    global precision_avg\n",
    "    global recall_avg\n",
    "    global f_avg\n",
    "    accuracy_avg += accuracy\n",
    "    precision_avg += precision\n",
    "    recall_avg += recall\n",
    "    f_avg += fmeasure\n",
    "    print \"accuracy: \" + str(accuracy)\n",
    "    print \"precision: \" + str(precision)\n",
    "    print \"recall: \" + str(recall)\n",
    "    print \"f-measure: \" + str(fmeasure)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Script starts here\n",
    "\n",
    "#select the filename here\n",
    "filename = \"project3_dataset1pre\"\n",
    "#filename = \"project3_dataset2pre\"\n",
    "#filename = \"project3_dataset1\"\n",
    "#filename = \"project3_dataset1\"\n",
    "\n",
    "\n",
    "data = np.genfromtxt(filename+'.txt',dtype='str',delimiter='\\t')\n",
    "\n",
    "numCols = data.shape[1]\n",
    "numRows = data.shape[0]\n",
    "\n",
    "accuracy_avg = 0\n",
    "precision_avg = 0\n",
    "recall_avg = 0\n",
    "f_avg = 0\n",
    "#print data[:,numCols-1]\n",
    "#print data0.shape[0]\n",
    "#print data1.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = 10 #no of folds\n",
    "n = numRows\n",
    "\n",
    "arr = np.arange(n)\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "list1 = []\n",
    "j = 0\n",
    "for i in range(k):\n",
    "    list1.append(np.empty(0, dtype=int))\n",
    "\n",
    "for i in range(n):\n",
    "    list1[j] = np.append(list1[j],arr[i])\n",
    "    if(j==k-1):\n",
    "        j = 0\n",
    "    else:\n",
    "        j = j+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22,4,1,30\n",
      "accuracy: 0.912280701754\n",
      "precision: 0.95652173913\n",
      "recall: 0.846153846154\n",
      "f-measure: 0.897959183673\n",
      "18,0,5,34\n",
      "accuracy: 0.912280701754\n",
      "precision: 0.782608695652\n",
      "recall: 1.0\n",
      "f-measure: 0.878048780488\n",
      "19,1,3,34\n",
      "accuracy: 0.929824561404\n",
      "precision: 0.863636363636\n",
      "recall: 0.95\n",
      "f-measure: 0.904761904762\n",
      "18,2,3,34\n",
      "accuracy: 0.912280701754\n",
      "precision: 0.857142857143\n",
      "recall: 0.9\n",
      "f-measure: 0.878048780488\n",
      "19,4,0,34\n",
      "accuracy: 0.929824561404\n",
      "precision: 1.0\n",
      "recall: 0.826086956522\n",
      "f-measure: 0.904761904762\n",
      "16,2,2,37\n",
      "accuracy: 0.929824561404\n",
      "precision: 0.888888888889\n",
      "recall: 0.888888888889\n",
      "f-measure: 0.888888888889\n",
      "19,3,0,35\n",
      "accuracy: 0.947368421053\n",
      "precision: 1.0\n",
      "recall: 0.863636363636\n",
      "f-measure: 0.926829268293\n",
      "18,2,2,35\n",
      "accuracy: 0.929824561404\n",
      "precision: 0.9\n",
      "recall: 0.9\n",
      "f-measure: 0.9\n",
      "24,2,0,31\n",
      "accuracy: 0.964912280702\n",
      "precision: 1.0\n",
      "recall: 0.923076923077\n",
      "f-measure: 0.96\n",
      "19,0,2,35\n",
      "accuracy: 0.964285714286\n",
      "precision: 0.904761904762\n",
      "recall: 1.0\n",
      "f-measure: 0.95\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    testIndices = list1[i]\n",
    "    trainIndices = np.empty(0, dtype='int')\n",
    "    for j in range(k):\n",
    "        if j != i:\n",
    "            trainIndices = np.append(trainIndices, list1[j])\n",
    "    \n",
    "    Xtrain = data[trainIndices[:],:]\n",
    "    Xtest = data[testIndices[:],:]\n",
    "    naiveB()\n",
    "#print trainIndices[:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.933270676692\n",
      "Average precision: 0.915356044921\n",
      "Average recall: 0.909784297828\n",
      "Average f-measure: 0.908929871135\n"
     ]
    }
   ],
   "source": [
    "accuracy_avg = float(accuracy_avg)/float(k)\n",
    "print \"Average accuracy: \" + str(accuracy_avg)\n",
    "precision_avg = float(precision_avg)/float(k)\n",
    "print \"Average precision: \" + str(precision_avg)\n",
    "recall_avg = float(recall_avg)/float(k)\n",
    "print \"Average recall: \" + str(recall_avg)\n",
    "f_avg = float(f_avg)/float(k)\n",
    "print \"Average f-measure: \"+str(f_avg)\n",
    "\n",
    "# print data.shape\n",
    "# print Xtrain.shape\n",
    "# print Xtest.shape\n",
    "# print Xtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
